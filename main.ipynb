{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des packages nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use('fivethirtyeight')\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib\n",
    "import datetime\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupération des fonctions des autres notebooks et des dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code departement (ex : 75)44\n",
      "Numero4\n",
      "Nom de la voieRue Fouré\n",
      "VilleNantes\n",
      "Code postal44000\n"
     ]
    }
   ],
   "source": [
    "#Entree par l'utilisateur de info sur son domicile \n",
    "dep = (input(\"Code departement (ex : 75)\"))\n",
    "num = int(input(\"Numero\"))\n",
    "nom_voie = input(\"Nom de la voie\")\n",
    "ville = input('Ville')\n",
    "code_postal = input(\"Code postal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import levenstein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addresse_to_GPS(dep, num, nom_voie, ville, code_postal):\n",
    "    adresses_dep = pd.read_csv(\"https://adresse.data.gouv.fr/data/ban/adresses/latest/csv/adresses-\"+dep+\".csv.gz\", compression='gzip', sep=\";\", error_bad_lines=False) #recuperation des adresses postales correspondant au département de l'utilisateur\n",
    "    #Correction de l'ortographe de la ville et de la rue (si necessaire) pour que cela fit au mieux avec le dataframe\n",
    "    #On utilise pour cela la minimisation de la distance de Levenstein\n",
    "    \n",
    "    ville=levenstein.get_ville_correct(ville,adresses_dep) \n",
    "    nom_voie=levenstein.get_rue_corect(nom_voie,adresses_dep)\n",
    "\n",
    "    foyer_infos = adresses_dep[(adresses_dep[\"numero\"] == num) & (adresses_dep[\"nom_commune\"] == ville) & (adresses_dep[\"nom_voie\"] == nom_voie)] \n",
    "    foyer = foyer_infos.to_numpy()\n",
    "    foyer = foyer.tolist()\n",
    "\n",
    "    \n",
    "    longitude = foyer[0][12]\n",
    "    latitude = foyer[0][13]\n",
    "\n",
    "    return(longitude, latitude, ville, nom_voie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.546307, 47.214242)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long, lat, ville, nom_voie = addresse_to_GPS(dep, num, nom_voie, ville, code_postal) #On corrige au passage l'addresse\n",
    "long, lat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nucléaire "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupération des tables de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrales = pd.read_csv(\"DataSets/centrales_nucleaires.csv\",sep=',',encoding_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Nucleaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La centrale nucleaire la plus proche se situe à :\n",
      "9979.717702772043 Fessenheim\n",
      "Le risque nucléaire à cette adresse est de :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rNu = Nucleaire.nucleaire(long, lat, centrales)\n",
    "rNu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inondations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupération des tables de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_risque_inond=gpd.read_file(\"DataSets/Inondation//n_carte_inond_s.shp\") \n",
    "df_adresses = pd.read_csv(\"https://adresse.data.gouv.fr/data/ban/adresses/latest/csv/adresses-\"+dep+\".csv.gz\", compression='gzip', sep=\";\", error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inondation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gpd_adresses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m adresse_gpd\u001b[38;5;241m=\u001b[39minondation\u001b[38;5;241m.\u001b[39madresse_to_gpd(df_adresses)\n\u001b[0;32m----> 2\u001b[0m rIn\u001b[38;5;241m=\u001b[39m\u001b[43minondation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madresse_to_risque\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdep\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnom_voie\u001b[49m\u001b[43m,\u001b[49m\u001b[43mville\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcode_postal\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Python/ProjPythonENSAE2022/ProjPython/inondation.py:41\u001b[0m, in \u001b[0;36madresse_to_risque\u001b[0;34m(dep, num, nom_voie, ville, code_postal)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madresse_to_risque\u001b[39m(dep,num,nom_voie,ville,code_postal):\n\u001b[0;32m---> 41\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m(risque(\u001b[43madresse_to_geometry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdep\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnom_voie\u001b[49m\u001b[43m,\u001b[49m\u001b[43mville\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcode_postal\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[0;32m~/Python/ProjPythonENSAE2022/ProjPython/inondation.py:15\u001b[0m, in \u001b[0;36madresse_to_geometry\u001b[0;34m(dep, num, nom_voie, ville, code_postal)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madresse_to_geometry\u001b[39m(dep,num,nom_voie,ville,code_postal):\n\u001b[0;32m---> 15\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m(\u001b[43mgpd_adresses\u001b[49m[(gpd_adresses[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumero\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m num) \u001b[38;5;241m&\u001b[39m (gpd_adresses[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnom_commune\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m ville) \u001b[38;5;241m&\u001b[39m (gpd_adresses[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnom_voie\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m nom_voie)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gpd_adresses' is not defined"
     ]
    }
   ],
   "source": [
    "adresse_gpd=inondation.adresse_to_gpd(df_adresses)\n",
    "rIn=inondation.adresse_to_risque(dep,num,nom_voie,ville,code_postal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glissement de terrains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupération des tables de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mvtTerrains13 = pd.read_csv(\"DataSets/mouvement_terrain_13.csv\", sep = \";\")\n",
    "df_mvtTerrains31 = pd.read_csv(\"DataSets/mouvement_terrain_31.csv\", sep = \";\")\n",
    "df_mvtTerrains44 = pd.read_csv(\"DataSets/mouvement_terrain_44.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import des fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glissement_terrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long, lat = addresse_to_GPS(dep, num, nom_voie, ville, code_postal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico = glissement_terrain.event_less_10km(lat, long, df_mvtTerrains44)\n",
    "riGdT,quali_data= glissement_terrain.calcul_risque(dico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Secheresse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupération des tables de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import secheresse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rSe = secheresse.secheresse(dep, num, nom_voie, ville, code_postal) * 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pollution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupération des tables de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PM10 = pd.read_csv(\"DataSets/\"+dep+\"/PM10.csv\", sep = \";\")\n",
    "df_SO2 = pd.read_csv(\"DataSets/\"+dep+\"/SO2.csv\", sep = \";\")\n",
    "df_CO = pd.read_csv(\"DataSets/\"+dep+\"/CO.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pollution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rPol = Pollution.risque_polution(lat, long, df_CO, df_SO2, df_PM10)\n",
    "rPol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupération des tables de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp13 = pd.read_csv(\"DataSets/temperature_\"+dep+\".csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On modifie les tables pour les rendre exploitables\n",
    "df_temp13=temperature.preprocessing(df_temp13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On vérifie que l'on a bien au moins une mesure par semaine dans nos tables (pour pouvoir fixer la saisonalité à 52)\n",
    "temperature.test_saisonalité(df_temp13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temperature maximale journalière au cours du temps \n",
    "#On remarque une belle saisonalité annuelle, ce qui est particulièrement adapté dans le cadre d'une utilisation du model SARIMA\n",
    "temperature.plot_temperature(df_temp13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#décomposition de la série temporelle en composante saisonnelle, tendance et en bruit\n",
    "temperature.get_decomposition(df_temp13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retourne les prédiction de temprérature pour un horizon donné, les paramètres du model sont pré rentrés. \n",
    "#model entrainé entre 2010 et 2019 et testé sur 2019, 2020, 2021, mi 2022\n",
    "pred, pred_ci=temperature.get_prediction_graph(2030,df_temp13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Te = temperature.temperature_max(pred,pred_ci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rTe = (Te / 50) * 20\n",
    "rTe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_risque = [rNu, rPol, rSe, rTe, riGdT, rIn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_final = sum(vec_risque)\n",
    "note_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_graph = [elem/20 for i in vect_risque]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "\n",
    "proportions = vect_graph\n",
    "labels = ['Nucléaire', 'Inondation', 'Glissements de terrains', 'Sécheresse', 'Pollution', 'Température']\n",
    "N = len(proportions)\n",
    "proportions = np.append(proportions, 1)\n",
    "theta = np.linspace(0, 2 * np.pi, N, endpoint=False)\n",
    "x = np.append(np.sin(theta), 0)\n",
    "y = np.append(np.cos(theta), 0)\n",
    "triangles = [[N, i, (i + 1) % N] for i in range(N)]\n",
    "triang_backgr = tri.Triangulation(x, y, triangles)\n",
    "triang_foregr = tri.Triangulation(x * proportions, y * proportions, triangles)\n",
    "cmap = plt.cm.rainbow_r  # or plt.cm.hsv ?\n",
    "colors = np.linspace(0, 1, N + 1)\n",
    "plt.tripcolor(triang_backgr, colors, cmap=cmap, shading='gouraud', alpha=0.4)\n",
    "plt.tripcolor(triang_foregr, colors, cmap=cmap, shading='gouraud', alpha=0.8)\n",
    "plt.triplot(triang_backgr, color='white', lw=2)\n",
    "for label, color, xi, yi in zip(labels, colors, x, y):\n",
    "    plt.text(xi * 1.05, yi * 1.05, label,  # color=cmap(color),\n",
    "             ha='left' if xi > 0.1 else 'right' if xi < -0.1 else 'center',\n",
    "             va='bottom' if yi > 0.1 else 'top' if yi < -0.1 else 'center')\n",
    "plt.axis('off')\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.title(\"Répartition des risques\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
